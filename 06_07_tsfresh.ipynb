{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Загрузка и предобработка датасета</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BreathingType</th>\n",
       "      <th>TimeStamp_sec</th>\n",
       "      <th>FirstMarkerXCoord</th>\n",
       "      <th>FirstMarkerYCoord</th>\n",
       "      <th>FirstMarkerZCoord</th>\n",
       "      <th>SecondMarkerXCoord</th>\n",
       "      <th>SecondMarkerYCoord</th>\n",
       "      <th>SecondMarkerZCoord</th>\n",
       "      <th>ThirdMarkerXCoord</th>\n",
       "      <th>ThirdMarkerYCoord</th>\n",
       "      <th>ThirdMarkerZCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.689</td>\n",
       "      <td>-1.453</td>\n",
       "      <td>4.417</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.547</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111889</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-1.452</td>\n",
       "      <td>4.418</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.547</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-1.451</td>\n",
       "      <td>4.419</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.545</td>\n",
       "      <td>0.714</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262516</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>4.420</td>\n",
       "      <td>0.882</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.541</td>\n",
       "      <td>0.711</td>\n",
       "      <td>-1.608</td>\n",
       "      <td>4.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295620</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-1.449</td>\n",
       "      <td>4.420</td>\n",
       "      <td>0.883</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  BreathingType  TimeStamp_sec  FirstMarkerXCoord  FirstMarkerYCoord  \\\n",
       "0   1              0       0.058895              0.689             -1.453   \n",
       "1   1              0       0.111889              0.687             -1.452   \n",
       "2   1              0       0.158371              0.687             -1.451   \n",
       "3   1              0       0.262516              0.685             -1.450   \n",
       "4   1              0       0.295620              0.684             -1.449   \n",
       "\n",
       "   FirstMarkerZCoord  SecondMarkerXCoord  SecondMarkerYCoord  \\\n",
       "0              4.417               0.881              -1.544   \n",
       "1              4.418               0.881              -1.544   \n",
       "2              4.419               0.881              -1.544   \n",
       "3              4.420               0.882              -1.544   \n",
       "4              4.420               0.883              -1.544   \n",
       "\n",
       "   SecondMarkerZCoord  ThirdMarkerXCoord  ThirdMarkerYCoord  ThirdMarkerZCoord  \n",
       "0               4.547              0.718             -1.607              4.369  \n",
       "1               4.547              0.715             -1.607              4.371  \n",
       "2               4.545              0.714             -1.607              4.371  \n",
       "3               4.541              0.711             -1.608              4.373  \n",
       "4               4.540              0.709             -1.607              4.370  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузка датасета\n",
    "df = pd.read_csv('coords_data_numerated.csv')\n",
    "df = df.drop(columns=['Unnamed: 0', 'GSR'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimeStamp_sec</th>\n",
       "      <th>FirstMarkerXCoord</th>\n",
       "      <th>FirstMarkerYCoord</th>\n",
       "      <th>FirstMarkerZCoord</th>\n",
       "      <th>SecondMarkerXCoord</th>\n",
       "      <th>SecondMarkerYCoord</th>\n",
       "      <th>SecondMarkerZCoord</th>\n",
       "      <th>ThirdMarkerXCoord</th>\n",
       "      <th>ThirdMarkerYCoord</th>\n",
       "      <th>ThirdMarkerZCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230921</th>\n",
       "      <td>258</td>\n",
       "      <td>59.76925</td>\n",
       "      <td>1.063</td>\n",
       "      <td>-1.649</td>\n",
       "      <td>3.843</td>\n",
       "      <td>1.093</td>\n",
       "      <td>-1.839</td>\n",
       "      <td>3.624</td>\n",
       "      <td>1.030</td>\n",
       "      <td>-1.867</td>\n",
       "      <td>3.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230922</th>\n",
       "      <td>258</td>\n",
       "      <td>59.80188</td>\n",
       "      <td>1.062</td>\n",
       "      <td>-1.648</td>\n",
       "      <td>3.842</td>\n",
       "      <td>1.094</td>\n",
       "      <td>-1.841</td>\n",
       "      <td>3.625</td>\n",
       "      <td>1.030</td>\n",
       "      <td>-1.867</td>\n",
       "      <td>3.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230923</th>\n",
       "      <td>258</td>\n",
       "      <td>59.90696</td>\n",
       "      <td>1.062</td>\n",
       "      <td>-1.648</td>\n",
       "      <td>3.842</td>\n",
       "      <td>1.093</td>\n",
       "      <td>-1.841</td>\n",
       "      <td>3.624</td>\n",
       "      <td>1.030</td>\n",
       "      <td>-1.868</td>\n",
       "      <td>3.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230924</th>\n",
       "      <td>258</td>\n",
       "      <td>59.92954</td>\n",
       "      <td>1.063</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>3.842</td>\n",
       "      <td>1.094</td>\n",
       "      <td>-1.841</td>\n",
       "      <td>3.624</td>\n",
       "      <td>1.029</td>\n",
       "      <td>-1.868</td>\n",
       "      <td>3.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230925</th>\n",
       "      <td>258</td>\n",
       "      <td>59.99477</td>\n",
       "      <td>1.063</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>3.842</td>\n",
       "      <td>1.094</td>\n",
       "      <td>-1.841</td>\n",
       "      <td>3.623</td>\n",
       "      <td>1.030</td>\n",
       "      <td>-1.868</td>\n",
       "      <td>3.853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  TimeStamp_sec  FirstMarkerXCoord  FirstMarkerYCoord  \\\n",
       "230921  258       59.76925              1.063             -1.649   \n",
       "230922  258       59.80188              1.062             -1.648   \n",
       "230923  258       59.90696              1.062             -1.648   \n",
       "230924  258       59.92954              1.063             -1.647   \n",
       "230925  258       59.99477              1.063             -1.647   \n",
       "\n",
       "        FirstMarkerZCoord  SecondMarkerXCoord  SecondMarkerYCoord  \\\n",
       "230921              3.843               1.093              -1.839   \n",
       "230922              3.842               1.094              -1.841   \n",
       "230923              3.842               1.093              -1.841   \n",
       "230924              3.842               1.094              -1.841   \n",
       "230925              3.842               1.094              -1.841   \n",
       "\n",
       "        SecondMarkerZCoord  ThirdMarkerXCoord  ThirdMarkerYCoord  \\\n",
       "230921               3.624              1.030             -1.867   \n",
       "230922               3.625              1.030             -1.867   \n",
       "230923               3.624              1.030             -1.868   \n",
       "230924               3.624              1.029             -1.868   \n",
       "230925               3.623              1.030             -1.868   \n",
       "\n",
       "        ThirdMarkerZCoord  \n",
       "230921              3.859  \n",
       "230922              3.857  \n",
       "230923              3.855  \n",
       "230924              3.853  \n",
       "230925              3.853  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Определение выходного признака и входных признаков\n",
    "y = df['BreathingType']\n",
    "X = df.drop(columns=['BreathingType'])\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimeStamp_sec</th>\n",
       "      <th>FMX</th>\n",
       "      <th>FMY</th>\n",
       "      <th>FMZ</th>\n",
       "      <th>SMX</th>\n",
       "      <th>SMY</th>\n",
       "      <th>SMZ</th>\n",
       "      <th>TMX</th>\n",
       "      <th>TMY</th>\n",
       "      <th>TMZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.689</td>\n",
       "      <td>-1.453</td>\n",
       "      <td>4.417</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.547</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.111889</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-1.452</td>\n",
       "      <td>4.418</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.547</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-1.451</td>\n",
       "      <td>4.419</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.545</td>\n",
       "      <td>0.714</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.262516</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>4.420</td>\n",
       "      <td>0.882</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.541</td>\n",
       "      <td>0.711</td>\n",
       "      <td>-1.608</td>\n",
       "      <td>4.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.295620</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-1.449</td>\n",
       "      <td>4.420</td>\n",
       "      <td>0.883</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>4.370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  TimeStamp_sec    FMX    FMY    FMZ    SMX    SMY    SMZ    TMX    TMY  \\\n",
       "0   1       0.058895  0.689 -1.453  4.417  0.881 -1.544  4.547  0.718 -1.607   \n",
       "1   1       0.111889  0.687 -1.452  4.418  0.881 -1.544  4.547  0.715 -1.607   \n",
       "2   1       0.158371  0.687 -1.451  4.419  0.881 -1.544  4.545  0.714 -1.607   \n",
       "3   1       0.262516  0.685 -1.450  4.420  0.882 -1.544  4.541  0.711 -1.608   \n",
       "4   1       0.295620  0.684 -1.449  4.420  0.883 -1.544  4.540  0.709 -1.607   \n",
       "\n",
       "     TMZ  \n",
       "0  4.369  \n",
       "1  4.371  \n",
       "2  4.371  \n",
       "3  4.373  \n",
       "4  4.370  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#переименование столбцов\n",
    "dict_renames = {\n",
    "    'FirstMarkerXCoord' : 'FMX',\n",
    "    'FirstMarkerYCoord' : 'FMY',\n",
    "    'FirstMarkerZCoord' : 'FMZ',\n",
    "    'SecondMarkerXCoord' :  'SMX',\n",
    "    'SecondMarkerYCoord' : 'SMY',\n",
    "    'SecondMarkerZCoord' : 'SMZ',\n",
    "    'ThirdMarkerXCoord' : 'TMX',\n",
    "    'ThirdMarkerYCoord' : 'TMY',\n",
    "    'ThirdMarkerZCoord' : 'TMZ'\n",
    "}\n",
    "X = X.rename(columns=dict_renames)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Извлечение признаков с помощью библиотеки TSFresh</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "settings = tsfresh.feature_extraction.settings.ComprehensiveFCParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 30/30 [07:27<00:00, 14.92s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = tsfresh.extract_features(X, column_sort='TimeStamp_sec', column_id='id', default_fc_parameters=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMX__variance_larger_than_standard_deviation</th>\n",
       "      <th>SMX__has_duplicate_max</th>\n",
       "      <th>SMX__has_duplicate_min</th>\n",
       "      <th>SMX__has_duplicate</th>\n",
       "      <th>SMX__sum_values</th>\n",
       "      <th>SMX__abs_energy</th>\n",
       "      <th>SMX__mean_abs_change</th>\n",
       "      <th>SMX__mean_change</th>\n",
       "      <th>SMX__mean_second_derivative_central</th>\n",
       "      <th>SMX__median</th>\n",
       "      <th>...</th>\n",
       "      <th>FMZ__fourier_entropy__bins_5</th>\n",
       "      <th>FMZ__fourier_entropy__bins_10</th>\n",
       "      <th>FMZ__fourier_entropy__bins_100</th>\n",
       "      <th>FMZ__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>FMZ__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>FMZ__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>FMZ__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>FMZ__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>FMZ__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>FMZ__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>786.339</td>\n",
       "      <td>686.379751</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204871</td>\n",
       "      <td>0.367289</td>\n",
       "      <td>0.929162</td>\n",
       "      <td>1.472701</td>\n",
       "      <td>2.419640</td>\n",
       "      <td>3.438875</td>\n",
       "      <td>4.449709</td>\n",
       "      <td>5.273135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.435429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>802.607</td>\n",
       "      <td>715.117611</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-5.561735e-07</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183378</td>\n",
       "      <td>0.310337</td>\n",
       "      <td>0.842774</td>\n",
       "      <td>1.562161</td>\n",
       "      <td>2.638883</td>\n",
       "      <td>3.795032</td>\n",
       "      <td>4.872082</td>\n",
       "      <td>5.708663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.417429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>773.539</td>\n",
       "      <td>664.234557</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-5.561735e-07</td>\n",
       "      <td>0.856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.215617</td>\n",
       "      <td>0.758199</td>\n",
       "      <td>1.515849</td>\n",
       "      <td>2.540378</td>\n",
       "      <td>3.625466</td>\n",
       "      <td>4.631890</td>\n",
       "      <td>5.442175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.445286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>894.241</td>\n",
       "      <td>887.645061</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.112347e-06</td>\n",
       "      <td>0.995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.442198</td>\n",
       "      <td>1.338456</td>\n",
       "      <td>2.129546</td>\n",
       "      <td>2.938742</td>\n",
       "      <td>3.717525</td>\n",
       "      <td>4.405405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.298143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>749.086</td>\n",
       "      <td>622.802878</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249958</td>\n",
       "      <td>0.433549</td>\n",
       "      <td>1.201067</td>\n",
       "      <td>1.343022</td>\n",
       "      <td>2.175330</td>\n",
       "      <td>3.074689</td>\n",
       "      <td>4.002324</td>\n",
       "      <td>4.823140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.238000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SMX__variance_larger_than_standard_deviation  SMX__has_duplicate_max  \\\n",
       "1                                           0.0                     1.0   \n",
       "2                                           0.0                     1.0   \n",
       "3                                           0.0                     0.0   \n",
       "4                                           0.0                     1.0   \n",
       "5                                           0.0                     1.0   \n",
       "\n",
       "   SMX__has_duplicate_min  SMX__has_duplicate  SMX__sum_values  \\\n",
       "1                     1.0                 1.0          786.339   \n",
       "2                     1.0                 1.0          802.607   \n",
       "3                     1.0                 1.0          773.539   \n",
       "4                     1.0                 1.0          894.241   \n",
       "5                     1.0                 1.0          749.086   \n",
       "\n",
       "   SMX__abs_energy  SMX__mean_abs_change  SMX__mean_change  \\\n",
       "1       686.379751              0.000353         -0.000004   \n",
       "2       715.117611              0.000334         -0.000041   \n",
       "3       664.234557              0.000439         -0.000026   \n",
       "4       887.645061              0.000349         -0.000007   \n",
       "5       622.802878              0.000310          0.000014   \n",
       "\n",
       "   SMX__mean_second_derivative_central  SMX__median  ...  \\\n",
       "1                         0.000000e+00        0.875  ...   \n",
       "2                        -5.561735e-07        0.891  ...   \n",
       "3                        -5.561735e-07        0.856  ...   \n",
       "4                        -1.112347e-06        0.995  ...   \n",
       "5                         0.000000e+00        0.831  ...   \n",
       "\n",
       "   FMZ__fourier_entropy__bins_5  FMZ__fourier_entropy__bins_10  \\\n",
       "1                      0.204871                       0.367289   \n",
       "2                      0.183378                       0.310337   \n",
       "3                      0.136002                       0.215617   \n",
       "4                      0.090729                       0.090729   \n",
       "5                      0.249958                       0.433549   \n",
       "\n",
       "   FMZ__fourier_entropy__bins_100  \\\n",
       "1                        0.929162   \n",
       "2                        0.842774   \n",
       "3                        0.758199   \n",
       "4                        0.442198   \n",
       "5                        1.201067   \n",
       "\n",
       "   FMZ__permutation_entropy__dimension_3__tau_1  \\\n",
       "1                                      1.472701   \n",
       "2                                      1.562161   \n",
       "3                                      1.515849   \n",
       "4                                      1.338456   \n",
       "5                                      1.343022   \n",
       "\n",
       "   FMZ__permutation_entropy__dimension_4__tau_1  \\\n",
       "1                                      2.419640   \n",
       "2                                      2.638883   \n",
       "3                                      2.540378   \n",
       "4                                      2.129546   \n",
       "5                                      2.175330   \n",
       "\n",
       "   FMZ__permutation_entropy__dimension_5__tau_1  \\\n",
       "1                                      3.438875   \n",
       "2                                      3.795032   \n",
       "3                                      3.625466   \n",
       "4                                      2.938742   \n",
       "5                                      3.074689   \n",
       "\n",
       "   FMZ__permutation_entropy__dimension_6__tau_1  \\\n",
       "1                                      4.449709   \n",
       "2                                      4.872082   \n",
       "3                                      4.631890   \n",
       "4                                      3.717525   \n",
       "5                                      4.002324   \n",
       "\n",
       "   FMZ__permutation_entropy__dimension_7__tau_1  \\\n",
       "1                                      5.273135   \n",
       "2                                      5.708663   \n",
       "3                                      5.442175   \n",
       "4                                      4.405405   \n",
       "5                                      4.823140   \n",
       "\n",
       "   FMZ__query_similarity_count__query_None__threshold_0.0  \\\n",
       "1                                                NaN        \n",
       "2                                                NaN        \n",
       "3                                                NaN        \n",
       "4                                                NaN        \n",
       "5                                                NaN        \n",
       "\n",
       "   FMZ__mean_n_absolute_max__number_of_maxima_7  \n",
       "1                                      4.435429  \n",
       "2                                      4.417429  \n",
       "3                                      4.445286  \n",
       "4                                      4.298143  \n",
       "5                                      4.238000  \n",
       "\n",
       "[5 rows x 7047 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = df[['id', 'BreathingType']].drop_duplicates()\n",
    "unique_pairs = unique_pairs.reset_index(drop=True)\n",
    "y = unique_pairs\n",
    "y.index = y['id']\n",
    "y = y.drop(columns=['id'])\n",
    "y = pd.Series(y['BreathingType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1      0\n",
       "2      1\n",
       "3      2\n",
       "4      0\n",
       "5      1\n",
       "      ..\n",
       "254    1\n",
       "255    2\n",
       "256    0\n",
       "257    1\n",
       "258    2\n",
       "Name: BreathingType, Length: 258, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FMY__agg_autocorrelation__f_agg_\"var\"__maxlag_40</th>\n",
       "      <th>FMY__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>FMY__partial_autocorrelation__lag_3</th>\n",
       "      <th>FMY__fourier_entropy__bins_10</th>\n",
       "      <th>FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"</th>\n",
       "      <th>FMY__linear_trend__attr_\"stderr\"</th>\n",
       "      <th>FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"mean\"</th>\n",
       "      <th>FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"</th>\n",
       "      <th>FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"min\"</th>\n",
       "      <th>FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"</th>\n",
       "      <th>...</th>\n",
       "      <th>FMZ__fft_coefficient__attr_\"real\"__coeff_37</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>TMX__ar_coefficient__coeff_1__k_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203342</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.222898</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.290971e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368654</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.325654</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.024434e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.368037</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.381678</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.141785e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180152</td>\n",
       "      <td>1.314077e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2.155637e-08</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>2.006410e-09</td>\n",
       "      <td>1.060953e-06</td>\n",
       "      <td>5.501077e-07</td>\n",
       "      <td>2.354984e-06</td>\n",
       "      <td>0.937611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029265</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.126742</td>\n",
       "      <td>0.280179</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.894390e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124672</td>\n",
       "      <td>7.638346e-07</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.435572e-08</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1.644779e-09</td>\n",
       "      <td>4.077468e-07</td>\n",
       "      <td>2.497918e-07</td>\n",
       "      <td>7.360300e-07</td>\n",
       "      <td>1.090171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.254175</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.265776</td>\n",
       "      <td>0.170467</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.465600e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123733</td>\n",
       "      <td>2.256864e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.989264e-09</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>3.413762e-10</td>\n",
       "      <td>2.613493e-07</td>\n",
       "      <td>1.969553e-07</td>\n",
       "      <td>1.301934e-07</td>\n",
       "      <td>0.831451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FMY__agg_autocorrelation__f_agg_\"var\"__maxlag_40  \\\n",
       "1                                          0.203342   \n",
       "2                                          0.368654   \n",
       "3                                          0.368037   \n",
       "4                                          0.029265   \n",
       "5                                          0.254175   \n",
       "\n",
       "   FMY__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "1                                           0.000013                    \n",
       "2                                           0.000055                    \n",
       "3                                           0.000052                    \n",
       "4                                           0.000003                    \n",
       "5                                           0.000007                    \n",
       "\n",
       "   FMY__partial_autocorrelation__lag_3  FMY__fourier_entropy__bins_10  \\\n",
       "1                            -0.222898                       0.136002   \n",
       "2                            -0.325654                       0.136002   \n",
       "3                            -0.381678                       0.136002   \n",
       "4                            -0.126742                       0.280179   \n",
       "5                            -0.265776                       0.170467   \n",
       "\n",
       "   FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"  \\\n",
       "1                                           0.000012                  \n",
       "2                                           0.000031                  \n",
       "3                                           0.000035                  \n",
       "4                                           0.000009                  \n",
       "5                                           0.000010                  \n",
       "\n",
       "   FMY__linear_trend__attr_\"stderr\"  \\\n",
       "1                      4.290971e-07   \n",
       "2                      1.024434e-06   \n",
       "3                      1.141785e-06   \n",
       "4                      2.894390e-07   \n",
       "5                      3.465600e-07   \n",
       "\n",
       "   FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"mean\"  \\\n",
       "1                                           0.000005                 \n",
       "2                                           0.000011                 \n",
       "3                                           0.000013                 \n",
       "4                                           0.000003                 \n",
       "5                                           0.000004                 \n",
       "\n",
       "   FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"  \\\n",
       "1                                           0.000005                \n",
       "2                                           0.000011                \n",
       "3                                           0.000013                \n",
       "4                                           0.000003                \n",
       "5                                           0.000004                \n",
       "\n",
       "   FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"min\"  \\\n",
       "1                                           0.000005                \n",
       "2                                           0.000011                \n",
       "3                                           0.000013                \n",
       "4                                           0.000003                \n",
       "5                                           0.000004                \n",
       "\n",
       "   FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"  ...  \\\n",
       "1                                           0.000013                ...   \n",
       "2                                           0.000032                ...   \n",
       "3                                           0.000034                ...   \n",
       "4                                           0.000009                ...   \n",
       "5                                           0.000011                ...   \n",
       "\n",
       "   FMZ__fft_coefficient__attr_\"real\"__coeff_37  \\\n",
       "1                                     0.156939   \n",
       "2                                     0.109409   \n",
       "3                                     0.180152   \n",
       "4                                     0.124672   \n",
       "5                                     0.123733   \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"  \\\n",
       "1                                       1.293342e-06                   \n",
       "2                                       3.231085e-07                   \n",
       "3                                       1.314077e-06                   \n",
       "4                                       7.638346e-07                   \n",
       "5                                       2.256864e-07                   \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"  \\\n",
       "1                                           0.000045                 \n",
       "2                                           0.000028                 \n",
       "3                                           0.000055                 \n",
       "4                                           0.000036                 \n",
       "5                                           0.000014                 \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"  \\\n",
       "1                                       2.114180e-08                 \n",
       "2                                       8.509713e-09                 \n",
       "3                                       2.155637e-08                 \n",
       "4                                       1.435572e-08                 \n",
       "5                                       2.989264e-09                 \n",
       "\n",
       "   TMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8  \\\n",
       "1                                           0.000635                 \n",
       "2                                           0.000358                 \n",
       "3                                           0.000715                 \n",
       "4                                           0.000398                 \n",
       "5                                           0.000254                 \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"  \\\n",
       "1                                       2.229450e-09                \n",
       "2                                       7.471823e-10                \n",
       "3                                       2.006410e-09                \n",
       "4                                       1.644779e-09                \n",
       "5                                       3.413762e-10                \n",
       "\n",
       "   TMX__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8  \\\n",
       "1                                       9.175544e-07                 \n",
       "2                                       3.678488e-07                 \n",
       "3                                       1.060953e-06                 \n",
       "4                                       4.077468e-07                 \n",
       "5                                       2.613493e-07                 \n",
       "\n",
       "   TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8  \\\n",
       "1                                       5.300205e-07                \n",
       "2                                       2.400601e-07                \n",
       "3                                       5.501077e-07                \n",
       "4                                       2.497918e-07                \n",
       "5                                       1.969553e-07                \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "1                                       1.498184e-06                 \n",
       "2                                       7.830371e-07                 \n",
       "3                                       2.354984e-06                 \n",
       "4                                       7.360300e-07                 \n",
       "5                                       1.301934e-07                 \n",
       "\n",
       "   TMX__ar_coefficient__coeff_1__k_10  \n",
       "1                            1.075671  \n",
       "2                            0.936582  \n",
       "3                            0.937611  \n",
       "4                            1.090171  \n",
       "5                            0.831451  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_filtered.to_csv('features_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_features = features_filtered.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Добавление новых признаков в датасет</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date_Of_Birth</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Had_Covid</th>\n",
       "      <th>Begin_Of_Covid</th>\n",
       "      <th>End_Of_Covid</th>\n",
       "      <th>Lung_Damage</th>\n",
       "      <th>Damage_Percent</th>\n",
       "      <th>Breathing_Type</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>Sin_Period23</th>\n",
       "      <th>Sin_Amp23/Sin_Amp13</th>\n",
       "      <th>Sin_Amp12/Sin_Amp13</th>\n",
       "      <th>Sin_Amp12/Sin_Amp23</th>\n",
       "      <th>Sin_Omega23/Sin_Omega13</th>\n",
       "      <th>Sin_Omega12/Sin_Omega13</th>\n",
       "      <th>Sin_Omega12/Sin_Omega23</th>\n",
       "      <th>(Sin_Offset23/Sin_Offset13)^2</th>\n",
       "      <th>(Sin_Offset12/Sin_Offset13)^2</th>\n",
       "      <th>(Sin_Offset12/Sin_Offset23)^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178712</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.032392</td>\n",
       "      <td>-0.156378</td>\n",
       "      <td>-0.155622</td>\n",
       "      <td>-0.156309</td>\n",
       "      <td>-0.088206</td>\n",
       "      <td>-0.063808</td>\n",
       "      <td>-0.059907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183415</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>-0.029759</td>\n",
       "      <td>-0.151883</td>\n",
       "      <td>-0.154821</td>\n",
       "      <td>-0.159698</td>\n",
       "      <td>-0.088211</td>\n",
       "      <td>-0.063809</td>\n",
       "      <td>-0.059906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177844</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>-0.001792</td>\n",
       "      <td>-0.030606</td>\n",
       "      <td>-0.157144</td>\n",
       "      <td>-0.156177</td>\n",
       "      <td>-0.155971</td>\n",
       "      <td>-0.088215</td>\n",
       "      <td>-0.063811</td>\n",
       "      <td>-0.059905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182131</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>-0.002349</td>\n",
       "      <td>-0.030553</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.155988</td>\n",
       "      <td>-0.160060</td>\n",
       "      <td>-0.088219</td>\n",
       "      <td>-0.063815</td>\n",
       "      <td>-0.059905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191648</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>-0.001519</td>\n",
       "      <td>-0.031048</td>\n",
       "      <td>-0.165326</td>\n",
       "      <td>-0.156451</td>\n",
       "      <td>-0.137226</td>\n",
       "      <td>-0.088204</td>\n",
       "      <td>-0.063811</td>\n",
       "      <td>-0.059908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Date_Of_Birth Sex Had_Covid Begin_Of_Covid End_Of_Covid Lung_Damage  \\\n",
       "0   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "1   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "2   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "3   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "4   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "\n",
       "   Damage_Percent Breathing_Type  Frequency  ...  Sin_Period23  \\\n",
       "0       -0.207005        грудное  -0.144237  ...     -0.178712   \n",
       "1       -0.207005        грудное  -0.144237  ...     -0.183415   \n",
       "2       -0.207005        грудное  -0.144237  ...     -0.177844   \n",
       "3       -0.207005        грудное  -0.144237  ...     -0.182131   \n",
       "4       -0.207005        грудное  -0.144237  ...     -0.191648   \n",
       "\n",
       "  Sin_Amp23/Sin_Amp13  Sin_Amp12/Sin_Amp13  Sin_Amp12/Sin_Amp23  \\\n",
       "0            0.002273            -0.001832            -0.032392   \n",
       "1            0.002486            -0.001808            -0.029759   \n",
       "2            0.002607            -0.001792            -0.030606   \n",
       "3            0.002219            -0.002349            -0.030553   \n",
       "4            0.003473            -0.001519            -0.031048   \n",
       "\n",
       "   Sin_Omega23/Sin_Omega13  Sin_Omega12/Sin_Omega13  Sin_Omega12/Sin_Omega23  \\\n",
       "0                -0.156378                -0.155622                -0.156309   \n",
       "1                -0.151883                -0.154821                -0.159698   \n",
       "2                -0.157144                -0.156177                -0.155971   \n",
       "3                -0.152623                -0.155988                -0.160060   \n",
       "4                -0.165326                -0.156451                -0.137226   \n",
       "\n",
       "   (Sin_Offset23/Sin_Offset13)^2  (Sin_Offset12/Sin_Offset13)^2  \\\n",
       "0                      -0.088206                      -0.063808   \n",
       "1                      -0.088211                      -0.063809   \n",
       "2                      -0.088215                      -0.063811   \n",
       "3                      -0.088219                      -0.063815   \n",
       "4                      -0.088204                      -0.063811   \n",
       "\n",
       "   (Sin_Offset12/Sin_Offset23)^2  \n",
       "0                      -0.059907  \n",
       "1                      -0.059906  \n",
       "2                      -0.059905  \n",
       "3                      -0.059905  \n",
       "4                      -0.059908  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузка датасета\n",
    "data = pd.read_csv('breathes.csv')\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_2452\\2099544929.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n"
     ]
    }
   ],
   "source": [
    "#добавление новых признаков в датасет\n",
    "i = 0\n",
    "new_features_cols = new_features.columns\n",
    "for id in range(1,87):\n",
    "    for col in new_features_cols:\n",
    "        data.loc[(data['Breathing_Type'] == 'грудное') & (data['ID'] == id), col]= new_features.loc[i][col]\n",
    "    i += 1\n",
    "    for col in new_features_cols:\n",
    "        data.loc[(data['Breathing_Type'] == 'брюшное') & (data['ID'] == id), col] = new_features.loc[i][col]\n",
    "    i += 1\n",
    "    for col in new_features_cols:\n",
    "        data.loc[(data['Breathing_Type'] == 'смешанное') & (data['ID'] == id), col] = new_features.loc[i][col]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date_Of_Birth</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Had_Covid</th>\n",
       "      <th>Begin_Of_Covid</th>\n",
       "      <th>End_Of_Covid</th>\n",
       "      <th>Lung_Damage</th>\n",
       "      <th>Damage_Percent</th>\n",
       "      <th>Breathing_Type</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>FMZ__fft_coefficient__attr_\"real\"__coeff_37</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>TMX__ar_coefficient__coeff_1__k_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>грудное</td>\n",
       "      <td>-0.144237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>1.293342e-06</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.114180e-08</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>2.229450e-09</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>1.498184e-06</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>брюшное</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>брюшное</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>брюшное</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>брюшное</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>брюшное</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>брюшное</td>\n",
       "      <td>-0.464100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109409</td>\n",
       "      <td>3.231085e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>8.509713e-09</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>7.471823e-10</td>\n",
       "      <td>3.678488e-07</td>\n",
       "      <td>2.400601e-07</td>\n",
       "      <td>7.830371e-07</td>\n",
       "      <td>0.936582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>смешанное</td>\n",
       "      <td>-1.423688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180152</td>\n",
       "      <td>1.314077e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2.155637e-08</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>2.006410e-09</td>\n",
       "      <td>1.060953e-06</td>\n",
       "      <td>5.501077e-07</td>\n",
       "      <td>2.354984e-06</td>\n",
       "      <td>0.937611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>смешанное</td>\n",
       "      <td>-1.423688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180152</td>\n",
       "      <td>1.314077e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2.155637e-08</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>2.006410e-09</td>\n",
       "      <td>1.060953e-06</td>\n",
       "      <td>5.501077e-07</td>\n",
       "      <td>2.354984e-06</td>\n",
       "      <td>0.937611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>04.07.2003</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>00.00.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.207005</td>\n",
       "      <td>смешанное</td>\n",
       "      <td>-1.423688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180152</td>\n",
       "      <td>1.314077e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2.155637e-08</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>2.006410e-09</td>\n",
       "      <td>1.060953e-06</td>\n",
       "      <td>5.501077e-07</td>\n",
       "      <td>2.354984e-06</td>\n",
       "      <td>0.937611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Date_Of_Birth Sex Had_Covid Begin_Of_Covid End_Of_Covid Lung_Damage  \\\n",
       "0    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "1    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "2    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "3    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "4    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "5    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "6    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "7    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "8    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "9    1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "10   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "11   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "12   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "13   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "14   1    04.07.2003   M        No     00.00.0000   00.00.0000          No   \n",
       "\n",
       "    Damage_Percent Breathing_Type  Frequency  ...  \\\n",
       "0        -0.207005        грудное  -0.144237  ...   \n",
       "1        -0.207005        грудное  -0.144237  ...   \n",
       "2        -0.207005        грудное  -0.144237  ...   \n",
       "3        -0.207005        грудное  -0.144237  ...   \n",
       "4        -0.207005        грудное  -0.144237  ...   \n",
       "5        -0.207005        грудное  -0.144237  ...   \n",
       "6        -0.207005        брюшное  -0.464100  ...   \n",
       "7        -0.207005        брюшное  -0.464100  ...   \n",
       "8        -0.207005        брюшное  -0.464100  ...   \n",
       "9        -0.207005        брюшное  -0.464100  ...   \n",
       "10       -0.207005        брюшное  -0.464100  ...   \n",
       "11       -0.207005        брюшное  -0.464100  ...   \n",
       "12       -0.207005      смешанное  -1.423688  ...   \n",
       "13       -0.207005      смешанное  -1.423688  ...   \n",
       "14       -0.207005      смешанное  -1.423688  ...   \n",
       "\n",
       "    FMZ__fft_coefficient__attr_\"real\"__coeff_37  \\\n",
       "0                                      0.156939   \n",
       "1                                      0.156939   \n",
       "2                                      0.156939   \n",
       "3                                      0.156939   \n",
       "4                                      0.156939   \n",
       "5                                      0.156939   \n",
       "6                                      0.109409   \n",
       "7                                      0.109409   \n",
       "8                                      0.109409   \n",
       "9                                      0.109409   \n",
       "10                                     0.109409   \n",
       "11                                     0.109409   \n",
       "12                                     0.180152   \n",
       "13                                     0.180152   \n",
       "14                                     0.180152   \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"  \\\n",
       "0                                        1.293342e-06                  \n",
       "1                                        1.293342e-06                  \n",
       "2                                        1.293342e-06                  \n",
       "3                                        1.293342e-06                  \n",
       "4                                        1.293342e-06                  \n",
       "5                                        1.293342e-06                  \n",
       "6                                        3.231085e-07                  \n",
       "7                                        3.231085e-07                  \n",
       "8                                        3.231085e-07                  \n",
       "9                                        3.231085e-07                  \n",
       "10                                       3.231085e-07                  \n",
       "11                                       3.231085e-07                  \n",
       "12                                       1.314077e-06                  \n",
       "13                                       1.314077e-06                  \n",
       "14                                       1.314077e-06                  \n",
       "\n",
       "    TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"  \\\n",
       "0                                            0.000045                 \n",
       "1                                            0.000045                 \n",
       "2                                            0.000045                 \n",
       "3                                            0.000045                 \n",
       "4                                            0.000045                 \n",
       "5                                            0.000045                 \n",
       "6                                            0.000028                 \n",
       "7                                            0.000028                 \n",
       "8                                            0.000028                 \n",
       "9                                            0.000028                 \n",
       "10                                           0.000028                 \n",
       "11                                           0.000028                 \n",
       "12                                           0.000055                 \n",
       "13                                           0.000055                 \n",
       "14                                           0.000055                 \n",
       "\n",
       "    TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"  \\\n",
       "0                                        2.114180e-08                 \n",
       "1                                        2.114180e-08                 \n",
       "2                                        2.114180e-08                 \n",
       "3                                        2.114180e-08                 \n",
       "4                                        2.114180e-08                 \n",
       "5                                        2.114180e-08                 \n",
       "6                                        8.509713e-09                 \n",
       "7                                        8.509713e-09                 \n",
       "8                                        8.509713e-09                 \n",
       "9                                        8.509713e-09                 \n",
       "10                                       8.509713e-09                 \n",
       "11                                       8.509713e-09                 \n",
       "12                                       2.155637e-08                 \n",
       "13                                       2.155637e-08                 \n",
       "14                                       2.155637e-08                 \n",
       "\n",
       "    TMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8  \\\n",
       "0                                            0.000635                 \n",
       "1                                            0.000635                 \n",
       "2                                            0.000635                 \n",
       "3                                            0.000635                 \n",
       "4                                            0.000635                 \n",
       "5                                            0.000635                 \n",
       "6                                            0.000358                 \n",
       "7                                            0.000358                 \n",
       "8                                            0.000358                 \n",
       "9                                            0.000358                 \n",
       "10                                           0.000358                 \n",
       "11                                           0.000358                 \n",
       "12                                           0.000715                 \n",
       "13                                           0.000715                 \n",
       "14                                           0.000715                 \n",
       "\n",
       "    TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"  \\\n",
       "0                                        2.229450e-09                \n",
       "1                                        2.229450e-09                \n",
       "2                                        2.229450e-09                \n",
       "3                                        2.229450e-09                \n",
       "4                                        2.229450e-09                \n",
       "5                                        2.229450e-09                \n",
       "6                                        7.471823e-10                \n",
       "7                                        7.471823e-10                \n",
       "8                                        7.471823e-10                \n",
       "9                                        7.471823e-10                \n",
       "10                                       7.471823e-10                \n",
       "11                                       7.471823e-10                \n",
       "12                                       2.006410e-09                \n",
       "13                                       2.006410e-09                \n",
       "14                                       2.006410e-09                \n",
       "\n",
       "    TMX__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8  \\\n",
       "0                                        9.175544e-07                 \n",
       "1                                        9.175544e-07                 \n",
       "2                                        9.175544e-07                 \n",
       "3                                        9.175544e-07                 \n",
       "4                                        9.175544e-07                 \n",
       "5                                        9.175544e-07                 \n",
       "6                                        3.678488e-07                 \n",
       "7                                        3.678488e-07                 \n",
       "8                                        3.678488e-07                 \n",
       "9                                        3.678488e-07                 \n",
       "10                                       3.678488e-07                 \n",
       "11                                       3.678488e-07                 \n",
       "12                                       1.060953e-06                 \n",
       "13                                       1.060953e-06                 \n",
       "14                                       1.060953e-06                 \n",
       "\n",
       "    TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8  \\\n",
       "0                                        5.300205e-07                \n",
       "1                                        5.300205e-07                \n",
       "2                                        5.300205e-07                \n",
       "3                                        5.300205e-07                \n",
       "4                                        5.300205e-07                \n",
       "5                                        5.300205e-07                \n",
       "6                                        2.400601e-07                \n",
       "7                                        2.400601e-07                \n",
       "8                                        2.400601e-07                \n",
       "9                                        2.400601e-07                \n",
       "10                                       2.400601e-07                \n",
       "11                                       2.400601e-07                \n",
       "12                                       5.501077e-07                \n",
       "13                                       5.501077e-07                \n",
       "14                                       5.501077e-07                \n",
       "\n",
       "    TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "0                                        1.498184e-06                 \n",
       "1                                        1.498184e-06                 \n",
       "2                                        1.498184e-06                 \n",
       "3                                        1.498184e-06                 \n",
       "4                                        1.498184e-06                 \n",
       "5                                        1.498184e-06                 \n",
       "6                                        7.830371e-07                 \n",
       "7                                        7.830371e-07                 \n",
       "8                                        7.830371e-07                 \n",
       "9                                        7.830371e-07                 \n",
       "10                                       7.830371e-07                 \n",
       "11                                       7.830371e-07                 \n",
       "12                                       2.354984e-06                 \n",
       "13                                       2.354984e-06                 \n",
       "14                                       2.354984e-06                 \n",
       "\n",
       "    TMX__ar_coefficient__coeff_1__k_10  \n",
       "0                             1.075671  \n",
       "1                             1.075671  \n",
       "2                             1.075671  \n",
       "3                             1.075671  \n",
       "4                             1.075671  \n",
       "5                             1.075671  \n",
       "6                             0.936582  \n",
       "7                             0.936582  \n",
       "8                             0.936582  \n",
       "9                             0.936582  \n",
       "10                            0.936582  \n",
       "11                            0.936582  \n",
       "12                            0.937611  \n",
       "13                            0.937611  \n",
       "14                            0.937611  \n",
       "\n",
       "[15 rows x 262 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Подготовка датасета для тестирования</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#отбрасывание ненужных столбцов\n",
    "categorical_cols = ['Sex', 'Had_Covid', 'Lung_Damage', 'DominatorFreq']\n",
    "drop_columns = ['Date_Of_Birth', 'Begin_Of_Covid', 'End_Of_Covid'] + categorical_cols\n",
    "df = data.drop(columns=drop_columns)\n",
    "#целевой признак\n",
    "y = df['Breathing_Type']\n",
    "#определение численных признаков\n",
    "non_numerical_cols = ['ID', 'Breathing_Type']\n",
    "X = df.drop(columns=non_numerical_cols)\n",
    "#трансформация категориальных признаков\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#разделение на обучающую(70%) и тестовую (30%) выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "#расчет метрик по тесовой выборке\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"F1-score: \", f1)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "#расчет знамости признаков\n",
    "def calc_feature_importances(model, X_df):\n",
    "    importance = model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({'Feature': X_df.columns, 'Importance': importance})\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Тестирование новых признаков</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>BorutaPy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t253\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t187\n",
      "Tentative: \t45\n",
      "Rejected: \t21\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t187\n",
      "Tentative: \t45\n",
      "Rejected: \t21\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t187\n",
      "Tentative: \t45\n",
      "Rejected: \t21\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t187\n",
      "Tentative: \t45\n",
      "Rejected: \t21\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t199\n",
      "Tentative: \t33\n",
      "Rejected: \t21\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t199\n",
      "Tentative: \t33\n",
      "Rejected: \t21\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t199\n",
      "Tentative: \t33\n",
      "Rejected: \t21\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t199\n",
      "Tentative: \t33\n",
      "Rejected: \t21\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t202\n",
      "Tentative: \t28\n",
      "Rejected: \t23\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t202\n",
      "Tentative: \t28\n",
      "Rejected: \t23\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t202\n",
      "Tentative: \t28\n",
      "Rejected: \t23\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t206\n",
      "Tentative: \t22\n",
      "Rejected: \t25\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t206\n",
      "Tentative: \t22\n",
      "Rejected: \t25\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t206\n",
      "Tentative: \t22\n",
      "Rejected: \t25\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t207\n",
      "Tentative: \t21\n",
      "Rejected: \t25\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t207\n",
      "Tentative: \t21\n",
      "Rejected: \t25\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t207\n",
      "Tentative: \t21\n",
      "Rejected: \t25\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t207\n",
      "Tentative: \t21\n",
      "Rejected: \t25\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t208\n",
      "Tentative: \t20\n",
      "Rejected: \t25\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t208\n",
      "Tentative: \t20\n",
      "Rejected: \t25\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t208\n",
      "Tentative: \t20\n",
      "Rejected: \t25\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t19\n",
      "Rejected: \t25\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t19\n",
      "Rejected: \t25\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t19\n",
      "Rejected: \t25\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t211\n",
      "Tentative: \t15\n",
      "Rejected: \t27\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t211\n",
      "Tentative: \t15\n",
      "Rejected: \t27\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t212\n",
      "Tentative: \t14\n",
      "Rejected: \t27\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t214\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t214\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t11\n",
      "Rejected: \t27\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t9\n",
      "Rejected: \t29\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t215\n",
      "Tentative: \t9\n",
      "Rejected: \t29\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t216\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t217\n",
      "Tentative: \t7\n",
      "Rejected: \t29\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t6\n",
      "Rejected: \t29\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t218\n",
      "Tentative: \t4\n",
      "Rejected: \t29\n"
     ]
    }
   ],
   "source": [
    "X_new = feat_selector.fit_transform(X_np, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Damage_Percent',\n",
       " 'DominatorFreqPower',\n",
       " 'Sin_Phase12',\n",
       " 'Sin_Amp13',\n",
       " 'Sin_Phase13',\n",
       " 'Sin_Phase23',\n",
       " 'Sin_Omega23/Sin_Omega13',\n",
       " 'Sin_Omega12/Sin_Omega23',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.4',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.4',\n",
       " 'FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.2',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2',\n",
       " 'FMY__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.4',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.2',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.6',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.0',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2',\n",
       " 'FMY__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8',\n",
       " 'TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.4',\n",
       " 'TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2',\n",
       " 'FMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"',\n",
       " 'TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2',\n",
       " 'FMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"',\n",
       " 'TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.0',\n",
       " 'TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0',\n",
       " 'TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0',\n",
       " 'SMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"',\n",
       " 'TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"',\n",
       " 'TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Rank': feat_selector.ranking_, 'Support': feat_selector.support_})\n",
    "#feature_importance = feature_importance.sort_values('Rank', ascending=True)\n",
    "bad_features = feature_importance[feature_importance['Support'] == False]\n",
    "drop_columns = list(bad_features['Feature'])\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>D_1_2_Avg</th>\n",
       "      <th>D_2_3_Avg</th>\n",
       "      <th>Sin_Amp12</th>\n",
       "      <th>Sin_Freq12</th>\n",
       "      <th>Sin_Omega12</th>\n",
       "      <th>Sin_Offset12</th>\n",
       "      <th>Sin_Period12</th>\n",
       "      <th>Sin_Freq13</th>\n",
       "      <th>...</th>\n",
       "      <th>SMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.2</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"</th>\n",
       "      <th>FMZ__fft_coefficient__attr_\"real\"__coeff_37</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "      <th>TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>TMX__ar_coefficient__coeff_1__k_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.144237</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>-0.124027</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>-0.034874</td>\n",
       "      <td>-0.346438</td>\n",
       "      <td>-0.346438</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>-0.179298</td>\n",
       "      <td>-0.320825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144237</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>-0.063376</td>\n",
       "      <td>0.028864</td>\n",
       "      <td>-0.035017</td>\n",
       "      <td>-0.287699</td>\n",
       "      <td>-0.287699</td>\n",
       "      <td>0.027561</td>\n",
       "      <td>-0.180414</td>\n",
       "      <td>-0.308442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.144237</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>-0.083593</td>\n",
       "      <td>0.028864</td>\n",
       "      <td>-0.034989</td>\n",
       "      <td>-0.370410</td>\n",
       "      <td>-0.370410</td>\n",
       "      <td>0.027551</td>\n",
       "      <td>-0.178809</td>\n",
       "      <td>-0.314792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.144237</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>-0.103810</td>\n",
       "      <td>0.028864</td>\n",
       "      <td>-0.032681</td>\n",
       "      <td>-0.393970</td>\n",
       "      <td>-0.393970</td>\n",
       "      <td>0.027388</td>\n",
       "      <td>-0.178306</td>\n",
       "      <td>-0.345404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.144237</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>-0.103810</td>\n",
       "      <td>0.065830</td>\n",
       "      <td>-0.033667</td>\n",
       "      <td>3.960226</td>\n",
       "      <td>3.960226</td>\n",
       "      <td>0.027337</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>3.686541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>9.175544e-07</td>\n",
       "      <td>5.300205e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.075671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frequency  Amplitude  D_1_2_Avg  D_2_3_Avg  Sin_Amp12  Sin_Freq12  \\\n",
       "0  -0.144237   0.147009  -0.124027   0.004220  -0.034874   -0.346438   \n",
       "1  -0.144237   0.147009  -0.063376   0.028864  -0.035017   -0.287699   \n",
       "2  -0.144237   0.147009  -0.083593   0.028864  -0.034989   -0.370410   \n",
       "3  -0.144237   0.147009  -0.103810   0.028864  -0.032681   -0.393970   \n",
       "4  -0.144237   0.147009  -0.103810   0.065830  -0.033667    3.960226   \n",
       "\n",
       "   Sin_Omega12  Sin_Offset12  Sin_Period12  Sin_Freq13  ...  \\\n",
       "0    -0.346438      0.027031     -0.179298   -0.320825  ...   \n",
       "1    -0.287699      0.027561     -0.180414   -0.308442  ...   \n",
       "2    -0.370410      0.027551     -0.178809   -0.314792  ...   \n",
       "3    -0.393970      0.027388     -0.178306   -0.345404  ...   \n",
       "4     3.960226      0.027337     -0.196950    3.686541  ...   \n",
       "\n",
       "   SMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.2  \\\n",
       "0                                           0.000335                 \n",
       "1                                           0.000335                 \n",
       "2                                           0.000335                 \n",
       "3                                           0.000335                 \n",
       "4                                           0.000335                 \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"  \\\n",
       "0                                           0.000016                \n",
       "1                                           0.000016                \n",
       "2                                           0.000016                \n",
       "3                                           0.000016                \n",
       "4                                           0.000016                \n",
       "\n",
       "   FMZ__fft_coefficient__attr_\"real\"__coeff_37  \\\n",
       "0                                     0.156939   \n",
       "1                                     0.156939   \n",
       "2                                     0.156939   \n",
       "3                                     0.156939   \n",
       "4                                     0.156939   \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"  \\\n",
       "0                                           0.000001                   \n",
       "1                                           0.000001                   \n",
       "2                                           0.000001                   \n",
       "3                                           0.000001                   \n",
       "4                                           0.000001                   \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"  \\\n",
       "0                                           0.000045                 \n",
       "1                                           0.000045                 \n",
       "2                                           0.000045                 \n",
       "3                                           0.000045                 \n",
       "4                                           0.000045                 \n",
       "\n",
       "   TMX__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.8  \\\n",
       "0                                           0.000635                 \n",
       "1                                           0.000635                 \n",
       "2                                           0.000635                 \n",
       "3                                           0.000635                 \n",
       "4                                           0.000635                 \n",
       "\n",
       "   TMX__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8  \\\n",
       "0                                       9.175544e-07                 \n",
       "1                                       9.175544e-07                 \n",
       "2                                       9.175544e-07                 \n",
       "3                                       9.175544e-07                 \n",
       "4                                       9.175544e-07                 \n",
       "\n",
       "   TMX__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8  \\\n",
       "0                                       5.300205e-07                \n",
       "1                                       5.300205e-07                \n",
       "2                                       5.300205e-07                \n",
       "3                                       5.300205e-07                \n",
       "4                                       5.300205e-07                \n",
       "\n",
       "   TMX__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "0                                           0.000001                 \n",
       "1                                           0.000001                 \n",
       "2                                           0.000001                 \n",
       "3                                           0.000001                 \n",
       "4                                           0.000001                 \n",
       "\n",
       "   TMX__ar_coefficient__coeff_1__k_10  \n",
       "0                            1.075671  \n",
       "1                            1.075671  \n",
       "2                            1.075671  \n",
       "3                            1.075671  \n",
       "4                            1.075671  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = X.drop(columns=drop_columns)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Generic Univariate Select (Тест-фишера)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import GenericUnivariateSelect, f_classif\n",
    "\n",
    "selector = GenericUnivariateSelect(f_classif, mode='k_best', param=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_new = selector.fit_transform(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FMY__agg_autocorrelation__f_agg_\"var\"__maxlag_40</td>\n",
       "      <td>206.868797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FMY__partial_autocorrelation__lag_3</td>\n",
       "      <td>186.130765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FMY__fourier_entropy__bins_10</td>\n",
       "      <td>166.267675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FMY__fourier_entropy__bins_100</td>\n",
       "      <td>163.495489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>147.095832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sin_Amp12/Sin_Amp13</td>\n",
       "      <td>0.312955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sin_Period23</td>\n",
       "      <td>0.221363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Sin_Offset23/Sin_Offset13)^2</td>\n",
       "      <td>0.139079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sin_Offset13</td>\n",
       "      <td>0.136538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>SMZ__linear_trend__attr_\"pvalue\"</td>\n",
       "      <td>0.043785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature      Scores\n",
       "26    FMY__agg_autocorrelation__f_agg_\"var\"__maxlag_40  206.868797\n",
       "28                 FMY__partial_autocorrelation__lag_3  186.130765\n",
       "29                       FMY__fourier_entropy__bins_10  166.267675\n",
       "38                      FMY__fourier_entropy__bins_100  163.495489\n",
       "33   FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...  147.095832\n",
       "..                                                 ...         ...\n",
       "19                                 Sin_Amp12/Sin_Amp13    0.312955\n",
       "17                                        Sin_Period23    0.221363\n",
       "22                       (Sin_Offset23/Sin_Offset13)^2    0.139079\n",
       "11                                        Sin_Offset13    0.136538\n",
       "153                   SMZ__linear_trend__attr_\"pvalue\"    0.043785\n",
       "\n",
       "[218 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = selector.scores_\n",
    "feature_importance = pd.DataFrame({'Feature': X2.columns, 'Scores': importance})\n",
    "feature_importance = feature_importance.sort_values('Scores', ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance.to_excel('ftest_features.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generic Univariate Select (Mutual Info)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "selector = GenericUnivariateSelect(mutual_info_classif, mode='k_best', param=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = selector.fit_transform(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>FMZ__fft_coefficient__attr_\"real\"__coeff_37</td>\n",
       "      <td>1.092985</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>FMY__spkt_welch_density__coeff_2</td>\n",
       "      <td>1.090960</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_12</td>\n",
       "      <td>1.090916</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_14</td>\n",
       "      <td>1.090313</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>FMY__partial_autocorrelation__lag_4</td>\n",
       "      <td>1.088674</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sin_Freq23</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sin_Omega23</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sin_Period23</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>FMX__large_standard_deviation__r_0.15000000000...</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sin_Amp23</td>\n",
       "      <td>0.013608</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature    Scores  Support\n",
       "210        FMZ__fft_coefficient__attr_\"real\"__coeff_37  1.092985     True\n",
       "100                   FMY__spkt_welch_density__coeff_2  1.090960     True\n",
       "51          FMY__fft_coefficient__attr_\"abs\"__coeff_12  1.090916     True\n",
       "64          FMY__fft_coefficient__attr_\"abs\"__coeff_14  1.090313     True\n",
       "78                 FMY__partial_autocorrelation__lag_4  1.088674     True\n",
       "..                                                 ...       ...      ...\n",
       "14                                          Sin_Freq23  0.030357    False\n",
       "15                                         Sin_Omega23  0.030357    False\n",
       "17                                        Sin_Period23  0.028520    False\n",
       "126  FMX__large_standard_deviation__r_0.15000000000...  0.027014    False\n",
       "13                                           Sin_Amp23  0.013608    False\n",
       "\n",
       "[218 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = selector.scores_\n",
    "feature_importance = pd.DataFrame({'Feature': X2.columns, 'Scores': importance, 'Support': selector.get_support()})\n",
    "feature_importance = feature_importance.sort_values('Scores', ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_excel('mutual_features.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>LightGBM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделение на обучающую(70%) и тестовую (30%) выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',  # Многоклассовая классификация\n",
    "    'num_classes': 3,  # Количество классов\n",
    "    'metric': 'multi_logloss'  # Метрика оценки\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10929\n",
      "[LightGBM] [Info] Number of data points in the train set: 985, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -1.087507\n",
      "[LightGBM] [Info] Start training from score -1.069596\n",
      "[LightGBM] [Info] Start training from score -1.140069\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params, train_data, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1-score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       149\n",
      "           1       1.00      1.00      1.00       123\n",
      "           2       1.00      1.00      1.00       151\n",
      "\n",
      "    accuracy                           1.00       423\n",
      "   macro avg       1.00      1.00      1.00       423\n",
      "weighted avg       1.00      1.00      1.00       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = y_pred.argmax(axis=1)  # Преобразование вероятностей в классы\n",
    "\n",
    "calculate_metrics(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TMZ__agg_autocorrelation__f_agg_\"var\"__maxlag_40</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FMY__agg_autocorrelation__f_agg_\"var\"__maxlag_40</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"intercept\"__chunk...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FMZ__fft_coefficient__attr_\"real\"__coeff_37</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TMX__partial_autocorrelation__lag_2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TMX__agg_autocorrelation__f_agg_\"median\"__maxl...</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FMX__fft_coefficient__attr_\"abs\"__coeff_40</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TMX__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_14</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FMY__partial_autocorrelation__lag_4</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TMX__spkt_welch_density__coeff_5</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SMX__fft_coefficient__attr_\"abs\"__coeff_55</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FMX__partial_autocorrelation__lag_2</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FMY__ar_coefficient__coeff_10__k_10</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SMX__fft_coefficient__attr_\"abs\"__coeff_77</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FMY__partial_autocorrelation__lag_3</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TMX__agg_linear_trend__attr_\"intercept\"__chunk...</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SMX__fft_coefficient__attr_\"abs\"__coeff_69</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TMX__fft_coefficient__attr_\"abs\"__coeff_33</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_12</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TMX__fft_coefficient__attr_\"abs\"__coeff_40</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TMX__ar_coefficient__coeff_1__k_10</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_11</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FMY__augmented_dickey_fuller__attr_\"teststat\"_...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FMY__agg_autocorrelation__f_agg_\"mean\"__maxlag_40</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SMX__fft_coefficient__attr_\"abs\"__coeff_78</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_13</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FMY__fft_coefficient__attr_\"abs\"__coeff_10</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TMX__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FMY__partial_autocorrelation__lag_2</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"intercept\"__chunk...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FMY__spkt_welch_density__coeff_2</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TMX__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FMY__agg_autocorrelation__f_agg_\"median\"__maxl...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FMY__cid_ce__normalize_True</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FMY__variation_coefficient</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FMY__variance</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FMY__standard_deviation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Feature  Importance\n",
       "39   TMZ__agg_autocorrelation__f_agg_\"var\"__maxlag_40         370\n",
       "0    FMY__agg_autocorrelation__f_agg_\"var\"__maxlag_40         343\n",
       "1   FMY__agg_linear_trend__attr_\"intercept\"__chunk...         309\n",
       "48        FMZ__fft_coefficient__attr_\"real\"__coeff_37         307\n",
       "40                TMX__partial_autocorrelation__lag_2         300\n",
       "43  TMX__agg_autocorrelation__f_agg_\"median\"__maxl...         298\n",
       "31         FMX__fft_coefficient__attr_\"abs\"__coeff_40         292\n",
       "37  TMX__change_quantiles__f_agg_\"mean\"__isabs_Tru...         289\n",
       "17         FMY__fft_coefficient__attr_\"abs\"__coeff_14         287\n",
       "21                FMY__partial_autocorrelation__lag_4         279\n",
       "34                   TMX__spkt_welch_density__coeff_5         270\n",
       "33         SMX__fft_coefficient__attr_\"abs\"__coeff_55         267\n",
       "45                FMX__partial_autocorrelation__lag_2         261\n",
       "27                FMY__ar_coefficient__coeff_10__k_10         256\n",
       "36         SMX__fft_coefficient__attr_\"abs\"__coeff_77         252\n",
       "2                 FMY__partial_autocorrelation__lag_3         243\n",
       "47  TMX__agg_linear_trend__attr_\"intercept\"__chunk...         224\n",
       "44         SMX__fft_coefficient__attr_\"abs\"__coeff_69         219\n",
       "41         TMX__fft_coefficient__attr_\"abs\"__coeff_33         218\n",
       "9          FMY__fft_coefficient__attr_\"abs\"__coeff_12         212\n",
       "42         TMX__fft_coefficient__attr_\"abs\"__coeff_40         211\n",
       "49                 TMX__ar_coefficient__coeff_1__k_10         203\n",
       "32         FMY__fft_coefficient__attr_\"abs\"__coeff_11         202\n",
       "8   FMY__augmented_dickey_fuller__attr_\"teststat\"_...         188\n",
       "11  FMY__agg_autocorrelation__f_agg_\"mean\"__maxlag_40         187\n",
       "35         SMX__fft_coefficient__attr_\"abs\"__coeff_78         182\n",
       "15         FMY__fft_coefficient__attr_\"abs\"__coeff_13         179\n",
       "29         FMY__fft_coefficient__attr_\"abs\"__coeff_10         175\n",
       "38  TMX__change_quantiles__f_agg_\"mean\"__isabs_Tru...         170\n",
       "18                FMY__partial_autocorrelation__lag_2         147\n",
       "7   FMY__agg_linear_trend__attr_\"intercept\"__chunk...         144\n",
       "30                   FMY__spkt_welch_density__coeff_2         143\n",
       "46  TMX__agg_linear_trend__attr_\"stderr\"__chunk_le...         130\n",
       "24  FMY__agg_autocorrelation__f_agg_\"median\"__maxl...         129\n",
       "23                        FMY__cid_ce__normalize_True         119\n",
       "28  FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...         113\n",
       "22                         FMY__variation_coefficient         109\n",
       "3   FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...         100\n",
       "10  FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...          96\n",
       "25  FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...          90\n",
       "26  FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...          82\n",
       "12  FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...          78\n",
       "16  FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...          72\n",
       "13                                      FMY__variance          63\n",
       "5   FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...          42\n",
       "20  FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...          37\n",
       "4   FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...          33\n",
       "6   FMY__agg_linear_trend__attr_\"stderr\"__chunk_le...          23\n",
       "19  FMY__change_quantiles__f_agg_\"mean\"__isabs_Tru...          21\n",
       "14                            FMY__standard_deviation           0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model.feature_importance()\n",
    "\n",
    "feature_importance = pd.DataFrame({'Feature': selector.get_feature_names_out(), 'Importance': importance})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_excel('lightGBM_mutual_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
